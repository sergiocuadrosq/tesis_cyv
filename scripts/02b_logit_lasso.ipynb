{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91df3ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3053c080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24232 entries, 0 to 24231\n",
      "Columns: 136 entries, status_inf to ratiodep\n",
      "dtypes: bool(127), float64(4), int64(5)\n",
      "memory usage: 4.6 MB\n"
     ]
    }
   ],
   "source": [
    "# Cargar el archivo CSV\n",
    "data_lasso = pd.read_csv(r\"../data/final/1_panel/3_modelling/df_model_post_tratamiento_estadistico.csv\")\n",
    "data_lasso = data_lasso.dropna()\n",
    "data_lasso.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff9b33d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de variables seleccionadas: 27\n",
      "categoria_trabajador_3   -0.027241\n",
      "ingtrabw                 -0.023981\n",
      "edad                     -0.017875\n",
      "trabajopara_2            -0.016890\n",
      "estadocivil_2            -0.007356\n",
      "sector_trabajador_3      -0.006025\n",
      "tuvootrotrabajo_2        -0.002856\n",
      "area_1                   -0.001698\n",
      "internet_1               -0.001149\n",
      "onp_1                    -0.000678\n",
      "niveleduc_8              -0.000529\n",
      "hospital_seguro_1        -0.000376\n",
      "niveleduc_4               0.000014\n",
      "niveleduc_5               0.001387\n",
      "pobreza_2                 0.002077\n",
      "puestosalud_1             0.002327\n",
      "materialtechos_4          0.003159\n",
      "sector_trabajador_8       0.005830\n",
      "personas_ingresos         0.006604\n",
      "materialpisos_6           0.007035\n",
      "usointernet_2             0.007140\n",
      "tipocontrato_2            0.009686\n",
      "tipocontrato_7            0.010356\n",
      "sis_1                     0.014623\n",
      "combustible               0.015280\n",
      "ciiu_6c_3                 0.019075\n",
      "categoria_trabajador_2    0.028170\n",
      "dtype: float64\n",
      "\n",
      "Classification Report para este pliegue:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.11      0.20      4989\n",
      "           1       0.19      0.99      0.32      1069\n",
      "\n",
      "    accuracy                           0.27      6058\n",
      "   macro avg       0.58      0.55      0.26      6058\n",
      "weighted avg       0.84      0.27      0.22      6058\n",
      "\n",
      "\n",
      "Classification Report para este pliegue:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.09      0.16      4988\n",
      "           1       0.19      0.99      0.32      1070\n",
      "\n",
      "    accuracy                           0.25      6058\n",
      "   macro avg       0.58      0.54      0.24      6058\n",
      "weighted avg       0.84      0.25      0.19      6058\n",
      "\n",
      "\n",
      "Classification Report para este pliegue:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.11      0.20      4988\n",
      "           1       0.19      0.98      0.32      1070\n",
      "\n",
      "    accuracy                           0.26      6058\n",
      "   macro avg       0.58      0.55      0.26      6058\n",
      "weighted avg       0.83      0.26      0.22      6058\n",
      "\n",
      "\n",
      "Classification Report para este pliegue:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.10      0.18      4988\n",
      "           1       0.19      0.99      0.32      1070\n",
      "\n",
      "    accuracy                           0.26      6058\n",
      "   macro avg       0.58      0.54      0.25      6058\n",
      "weighted avg       0.84      0.26      0.20      6058\n",
      "\n",
      "\n",
      "AUC promedio en validación cruzada: 0.732 (0.007)\n",
      "Accuracy promedio en validación cruzada: 0.259 (0.007)\n",
      "Precision promedio para la clase 1 en validación cruzada: 0.191 (0.001)\n",
      "Precision promedio macro en validación cruzada: 0.582 (0.002)\n",
      "Recall promedio para la clase 1 en validación cruzada: 0.986 (0.003)\n",
      "Recall promedio macro en validación cruzada: 0.545 (0.004)\n",
      "F1-score promedio para la clase 1 en validación cruzada: 0.320 (0.002)\n",
      "F1-score promedio macro en validación cruzada: 0.253 (0.008)\n",
      "F1-score promedio en validación cruzada: 0.320 (0.002)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, recall_score, f1_score, accuracy_score, precision_score\n",
    "import numpy as np\n",
    "\n",
    "# Variable objetivo\n",
    "y = data_lasso['status_inf']\n",
    "\n",
    "# Variables explicativas\n",
    "X = data_lasso.drop(columns=['status_inf'])\n",
    "\n",
    "# Escalar las características\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Ajustar el modelo Lasso con un valor fijo de alpha\n",
    "alpha_value = 0.01  # Ajusta este valor según lo necesario\n",
    "lasso = Lasso(alpha=alpha_value, random_state=42)\n",
    "lasso.fit(X_scaled, y)\n",
    "\n",
    "# Selección de variables útiles (coeficientes ≠ 0)\n",
    "coef = pd.Series(lasso.coef_, index=X.columns)\n",
    "coef_no_cero = coef[coef != 0]\n",
    "print(\"Número de variables seleccionadas:\", coef_no_cero.shape[0])\n",
    "\n",
    "# Variables descartadas\n",
    "coef_cero = coef[coef == 0]\n",
    "\n",
    "# Mostrar las variables seleccionadas\n",
    "print(coef_no_cero.sort_values())\n",
    "\n",
    "# Lista de variables útiles seleccionadas\n",
    "variables_utiles = coef_no_cero.index.tolist()\n",
    "\n",
    "# Usar las variables seleccionadas para el modelo Logit\n",
    "X_lasso_selected = data_lasso[variables_utiles]\n",
    "\n",
    "# Escalar las características seleccionadas\n",
    "X_lasso_scaled = scaler.fit_transform(X_lasso_selected)\n",
    "\n",
    "# Inicializar el modelo Logit con balance de clases\n",
    "logit_bal = LogisticRegression(class_weight=\"balanced\", max_iter=5000)\n",
    "\n",
    "# Validación cruzada de 4 pliegues\n",
    "cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "# Inicializar listas para almacenar las métricas de cada pliegue\n",
    "auc_cv_scores = []\n",
    "accuracy_cv_scores = []\n",
    "precision_class_1_cv_scores = []  # Guardaremos la precision para la clase 1\n",
    "precision_macro_cv_scores = []  # Guardaremos la precision macro (promedio)\n",
    "recall_class_1_cv_scores = []  # Guardaremos el recall para la clase 1\n",
    "recall_macro_cv_scores = []  # Guardaremos el recall macro (promedio)\n",
    "f1_class_1_cv_scores = []  # F1-Score para clase 1\n",
    "f1_macro_cv_scores = []  # F1-Score macro\n",
    "f1_cv_scores = []\n",
    "recall_cv_scores = []\n",
    "\n",
    "# Recalcular las métricas para cada pliegue\n",
    "for train_idx, test_idx in cv.split(X_lasso_scaled, y):\n",
    "    X_train, X_test = X_lasso_scaled[train_idx], X_lasso_scaled[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    # Entrenar el modelo en el pliegue de entrenamiento\n",
    "    logit_bal.fit(X_train, y_train)\n",
    "    \n",
    "    # Obtener las probabilidades predichas para AUC\n",
    "    y_proba_test = logit_bal.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calcular AUC para este pliegue\n",
    "    auc_cv_scores.append(roc_auc_score(y_test, y_proba_test))\n",
    "    \n",
    "    # Obtener las predicciones para las métricas de clasificación\n",
    "    y_pred_test = (y_proba_test >= umbral).astype(int)\n",
    "    \n",
    "    # Calcular Accuracy, Precision, Recall y F1-Score para todo el conjunto\n",
    "    accuracy_cv_scores.append(accuracy_score(y_test, y_pred_test))\n",
    "    \n",
    "    # Calcular Precision para la clase 1\n",
    "    precision_class_1 = precision_score(y_test, y_pred_test, pos_label=1)\n",
    "    precision_class_1_cv_scores.append(precision_class_1)\n",
    "    \n",
    "    # Calcular Precision macro (promedio)\n",
    "    precision_macro = precision_score(y_test, y_pred_test, average='macro')\n",
    "    precision_macro_cv_scores.append(precision_macro)\n",
    "    \n",
    "    # Calcular Recall para la clase 1\n",
    "    recall_class_1 = recall_score(y_test, y_pred_test, pos_label=1)\n",
    "    recall_class_1_cv_scores.append(recall_class_1)\n",
    "    \n",
    "    # Calcular Recall macro (promedio)\n",
    "    recall_macro = recall_score(y_test, y_pred_test, average='macro')\n",
    "    recall_macro_cv_scores.append(recall_macro)\n",
    "    \n",
    "    # Calcular F1-Score para la clase 1\n",
    "    f1_class_1 = f1_score(y_test, y_pred_test, pos_label=1)\n",
    "    f1_class_1_cv_scores.append(f1_class_1)\n",
    "    \n",
    "    # Calcular F1-Score macro (promedio)\n",
    "    f1_macro = f1_score(y_test, y_pred_test, average='macro')\n",
    "    f1_macro_cv_scores.append(f1_macro)\n",
    "    \n",
    "    # Calcular F1-Score general\n",
    "    f1_cv_scores.append(f1_score(y_test, y_pred_test))\n",
    "    \n",
    "    # Calcular Recall general\n",
    "    recall_cv_scores.append(recall_score(y_test, y_pred_test))\n",
    "    \n",
    "    # Mostrar classification report para cada pliegue\n",
    "    print(f\"\\nClassification Report para este pliegue:\\n\", classification_report(y_test, y_pred_test))\n",
    "\n",
    "# Calcular la media y desviación estándar de las métricas\n",
    "mean_auc = np.mean(auc_cv_scores)\n",
    "std_auc = np.std(auc_cv_scores)\n",
    "\n",
    "mean_accuracy = np.mean(accuracy_cv_scores)\n",
    "std_accuracy = np.std(accuracy_cv_scores)\n",
    "\n",
    "mean_precision_class_1 = np.mean(precision_class_1_cv_scores)\n",
    "std_precision_class_1 = np.std(precision_class_1_cv_scores)\n",
    "\n",
    "mean_precision_macro = np.mean(precision_macro_cv_scores)\n",
    "std_precision_macro = np.std(precision_macro_cv_scores)\n",
    "\n",
    "mean_recall_class_1 = np.mean(recall_class_1_cv_scores)\n",
    "std_recall_class_1 = np.std(recall_class_1_cv_scores)\n",
    "\n",
    "mean_recall_macro = np.mean(recall_macro_cv_scores)\n",
    "std_recall_macro = np.std(recall_macro_cv_scores)\n",
    "\n",
    "mean_f1_class_1 = np.mean(f1_class_1_cv_scores)\n",
    "std_f1_class_1 = np.std(f1_class_1_cv_scores)\n",
    "\n",
    "mean_f1_macro = np.mean(f1_macro_cv_scores)\n",
    "std_f1_macro = np.std(f1_macro_cv_scores)\n",
    "\n",
    "mean_f1 = np.mean(f1_cv_scores)\n",
    "std_f1 = np.std(f1_cv_scores)\n",
    "\n",
    "# Imprimir los resultados finales con las métricas y sus desviaciones estándar\n",
    "print(f\"\\nAUC promedio en validación cruzada: {mean_auc:.3f} ({std_auc:.3f})\")\n",
    "print(f\"Accuracy promedio en validación cruzada: {mean_accuracy:.3f} ({std_accuracy:.3f})\")\n",
    "print(f\"Precision promedio para la clase 1 en validación cruzada: {mean_precision_class_1:.3f} ({std_precision_class_1:.3f})\")\n",
    "print(f\"Precision promedio macro en validación cruzada: {mean_precision_macro:.3f} ({std_precision_macro:.3f})\")\n",
    "print(f\"Recall promedio para la clase 1 en validación cruzada: {mean_recall_class_1:.3f} ({std_recall_class_1:.3f})\")\n",
    "print(f\"Recall promedio macro en validación cruzada: {mean_recall_macro:.3f} ({std_recall_macro:.3f})\")\n",
    "print(f\"F1-score promedio para la clase 1 en validación cruzada: {mean_f1_class_1:.3f} ({std_f1_class_1:.3f})\")\n",
    "print(f\"F1-score promedio macro en validación cruzada: {mean_f1_macro:.3f} ({std_f1_macro:.3f})\")\n",
    "print(f\"F1-score promedio en validación cruzada: {mean_f1:.3f} ({std_f1:.3f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
